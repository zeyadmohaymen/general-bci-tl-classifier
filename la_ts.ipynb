{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.datasets import eegbci\n",
    "from mne.io import concatenate_raws, read_raw_edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from C:\\Users\\zeyad\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0\\S001\\S001R06.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from C:\\Users\\zeyad\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0\\S001\\S001R10.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "Extracting EDF parameters from C:\\Users\\zeyad\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0\\S001\\S001R14.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 19999  =      0.000 ...   124.994 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Adding average EEG reference projection.\n",
      "1 projection items deactivated\n",
      "Average reference projection was added, but has not been applied yet. Use the apply_proj method to apply it.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>August 12, 2009  16:15:00 GMT</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            \n",
       "            <td>X</td>\n",
       "            \n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>67 points</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>64 EEG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>160.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>80.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Projections</th>\n",
       "                    <td>Average EEG reference : off</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Filenames</th>\n",
       "                    <td>S001R06.edf&lt;br&gt;S001R10.edf&lt;br&gt;S001R14.edf</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Duration</th>\n",
       "                    <td>00:06:15 (HH:MM:SS)</td>\n",
       "                </tr>\n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<RawEDF | S001R06.edf, 64 x 60000 (375.0 s), ~29.4 MB, data loaded>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = [6, 10, 14]  # motor imagery: hands vs feet\n",
    "\n",
    "source_fnames = eegbci.load_data(1, runs)\n",
    "source = concatenate_raws([read_raw_edf(f, preload=True) for f in source_fnames])\n",
    "eegbci.standardize(source)  # set channel names\n",
    "montage = make_standard_montage(\"standard_1005\")\n",
    "source.set_montage(montage)\n",
    "source.annotations.rename(dict(T0=\"rest\", T1=\"hands\", T2=\"feet\"))\n",
    "source.set_eeg_reference(projection=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'Fp1', 'Fpz', 'Fp2', 'AF7', 'AF3', 'AFz', 'AF4', 'AF8', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FT7', 'FT8', 'T7', 'T8', 'T9', 'T10', 'TP7', 'TP8', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'PO7', 'PO3', 'POz', 'PO4', 'PO8', 'O1', 'Oz', 'O2', 'Iz']\n"
     ]
    }
   ],
   "source": [
    "# print channel names\n",
    "print(source.ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 3 contiguous segments\n",
      "Setting up band-pass filter from 8 - 35 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 8.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 7.00 Hz)\n",
      "- Upper passband edge: 35.00 Hz\n",
      "- Upper transition bandwidth: 8.75 Hz (-6 dB cutoff frequency: 39.38 Hz)\n",
      "- Filter length: 265 samples (1.656 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Removing existing average EEG reference projection.\n",
      "Fitting ICA to data using 64 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Computing Extended Infomax ICA\n",
      "Fitting ICA took 22.1s.\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zeyad\\Documents\\repos\\general-bci-tl-classifier\\scripts\\raw_preprocessing.py:42: RuntimeWarning: The provided Raw instance is not filtered between 1 and 100 Hz. ICLabel was designed to classify features extracted from an EEG dataset bandpass filtered between 1 and 100 Hz (see the 'filter()' method for Raw and Epochs instances).\n",
      "  ica_labels = label_components(self.processed_raw, ica, method='iclabel')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 8 ICA components\n",
      "    Projecting back using 64 PCA components\n",
      "Used Annotations descriptions: ['feet', 'hands', 'rest']\n",
      "Ignoring annotation durations and creating fixed-duration epochs around annotation onsets.\n",
      "Not setting metadata\n",
      "90 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 90 events and 801 original time points ...\n",
      "3 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "from scripts.raw_preprocessing import Preprocessing\n",
    "\n",
    "source_preprocessing = Preprocessing(source)\n",
    "source_preprocessing.preprocess_raw()\n",
    "source_epochs = source_preprocessing.segment_into_epochs(['rest', 'hands', 'feet'], channels=[\"C3\", \"C4\", \"P3\", \"P4\", \"T7\", \"T8\", \"P7\", \"P8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs after event encoding [not feet vs feet] <Epochs |  87 events (all good), -1 â€“ 4 s, baseline off, ~4.3 MB, data loaded,\n",
      " 'not feet': 63\n",
      " 'feet': 24>\n",
      "Cropped Epochs to:  0.5 s --  3.5 s\n"
     ]
    }
   ],
   "source": [
    "# epochs preprocessing pipeline\n",
    "from scripts.epochs_preprocessing import EventsEncoder, EventsEqualizer, Cropper, EpochsSegmenter\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('events_encoder', EventsEncoder(counter_class=\"rest\")),\n",
    "    ('events_equalizer', EventsEqualizer()),\n",
    "    ('cropper', Cropper()),\n",
    "    ('segmenter', EpochsSegmenter())\n",
    "])\n",
    "\n",
    "source_epochs_p = pipeline.fit_transform(source_epochs.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3 2 3 2 3 1 3 2 3 1 3 1 3 2 3 2 3 1 3 1 3 2 3 2 3 1 3 1 2 3 1 3 1 3 2 3\n",
      " 1 3 2 3 2 3 1 3 1 3 2 3 2 3 1 3 1 3 2 3 1 1 3 2 3 1 3 2 3 2 3 1 3 2 3 1 3\n",
      " 2 3 1 3 1 3 2 3 1 3 2 3 1]\n",
      "[1 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 1 0 1 0 0 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 1 0 0 0 1 1 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0\n",
      " 0 0 1 0 1 0 0 0 1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(source_epochs.events[:,-1])\n",
    "print(source_epochs_p.events[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulate real time data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare calibration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibration data\n",
    "target_fnames = eegbci.load_data(2, [6])\n",
    "target = concatenate_raws([read_raw_edf(f, preload=True) for f in target_fnames])\n",
    "eegbci.standardize(target)\n",
    "target.set_montage(montage)\n",
    "target.annotations.rename(dict(T0=\"rest\", T1=\"hands\", T2=\"feet\"))\n",
    "target.set_eeg_reference(projection=True)\n",
    "\n",
    "# preprocessing\n",
    "target_preprocessing = Preprocessing(target)\n",
    "target_preprocessing.preprocess_raw()\n",
    "target_epochs = target_preprocessing.segment_into_epochs(['hands', 'feet'], channels=[\"C3\", \"C4\", \"P3\", \"P4\", \"T7\", \"T8\", \"P7\", \"P8\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label alignment & TS mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.label_alignment import LabelAlignment\n",
    "import numpy as np\n",
    "\n",
    "source_events = source_epochs.events[:, -1]\n",
    "la = LabelAlignment(target_epochs, concat=True)\n",
    "source_aligned, source_events = la.fit_transform(source_epochs.get_data(), source_events)\n",
    "\n",
    "# append target data to source data\n",
    "# source_aligned = np.concatenate([source_aligned, target_epochs.get_data()])\n",
    "# source_events = np.concatenate([source_events, target_epochs.events[:, -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scripts.ts_feature_extraction import tangent_space_mapping\n",
    "\n",
    "# source_ts = tangent_space_mapping(source_aligned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rt data\n",
    "rt_fnames = eegbci.load_data(2, [10, 14])\n",
    "rt = concatenate_raws([read_raw_edf(f, preload=True) for f in rt_fnames])\n",
    "eegbci.standardize(rt)\n",
    "rt.set_montage(montage)\n",
    "rt.annotations.rename(dict(T0=\"rest\", T1=\"hands\", T2=\"feet\"))\n",
    "rt.set_eeg_reference(projection=True)\n",
    "\n",
    "# preprocessing\n",
    "rt_preprocessing = Preprocessing(rt)\n",
    "rt_preprocessing.preprocess_raw()\n",
    "rt_epochs = rt_preprocessing.segment_into_epochs(['hands', 'feet'], channels=[\"C3\", \"C4\", \"P3\", \"P4\", \"T7\", \"T8\", \"P7\", \"P8\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from scripts.ts_feature_extraction import TangentSpaceMapping\n",
    "\n",
    "X = source_aligned\n",
    "y = source_events\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, y_train = X, y\n",
    "X_test = rt_epochs.get_data()\n",
    "y_test = rt_epochs.events[:, -1]\n",
    "\n",
    "# Create and fit the classifier\n",
    "lda =  LDA()\n",
    "clf = make_pipeline(TangentSpaceMapping(), lda)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute and plot the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
